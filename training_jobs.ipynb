{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/2.25.11 Python/3.12.9 Darwin/24.5.0 exe/x86_64\n"
     ]
    }
   ],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/29/25 16:42:20] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/29/25 16:42:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=795477;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=198879;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py#681\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">681</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=330760;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=218687;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py#681\u001b\\\u001b[2m681\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py#681\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">681</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=796943;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=277650;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/image_uris.py#681\u001b\\\u001b[2m681\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         huggingface-pytorch-training-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-06-29-22-42-20-036                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=732286;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=904303;file:///Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         huggingface-pytorch-training-\u001b[1;36m2025\u001b[0m-06-29-22-42-20-036                   \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-29 22:42:21 Starting - Starting the training job...\n",
      "2025-06-29 22:42:35 Starting - Preparing the instances for training...\n",
      "2025-06-29 22:43:03 Downloading - Downloading input data...\n",
      "2025-06-29 22:43:28 Downloading - Downloading the training image...............\n",
      "2025-06-29 22:46:25 Training - Training image download completed. Training in progress...bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "2025-06-29 22:46:37,922 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-06-29 22:46:37,942 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-06-29 22:46:37,956 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-06-29 22:46:37,960 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-06-29 22:46:39,099 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\n",
      "Collecting transformers==4.36.2 (from -r requirements.txt (line 1))\n",
      "Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.8/126.8 kB 10.1 MB/s eta 0:00:00\n",
      "Collecting peft==0.9.0 (from -r requirements.txt (line 2))\n",
      "Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting datasets==2.19.1 (from -r requirements.txt (line 3))\n",
      "Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate==0.27.2 (from -r requirements.txt (line 4))\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2->-r requirements.txt (line 1))\n",
      "Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.36.2->-r requirements.txt (line 1)) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft==0.9.0->-r requirements.txt (line 2)) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.9.0->-r requirements.txt (line 2)) (1.13.1+cu117)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets==2.19.1->-r requirements.txt (line 3)) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.9/site-packages (from datasets==2.19.1->-r requirements.txt (line 3)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets==2.19.1->-r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets==2.19.1->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==2.19.1->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets==2.19.1->-r requirements.txt (line 3)) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.9/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->-r requirements.txt (line 3)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets==2.19.1->-r requirements.txt (line 3)) (3.10.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.36.2->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.36.2->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.36.2->-r requirements.txt (line 1)) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.36.2->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==2.19.1->-r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==2.19.1->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==2.19.1->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.1->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.9/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.19.1->-r requirements.txt (line 3)) (0.2.0)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 105.4 MB/s eta 0:00:00\n",
      "Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.9/190.9 kB 30.7 MB/s eta 0:00:00\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.0/542.0 kB 57.9 MB/s eta 0:00:00\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.0/280.0 kB 36.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 125.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, accelerate, transformers, peft, datasets\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.13.3\n",
      "Uninstalling tokenizers-0.13.3:\n",
      "Successfully uninstalled tokenizers-0.13.3\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.33.0\n",
      "Uninstalling accelerate-0.33.0:\n",
      "Successfully uninstalled accelerate-0.33.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.26.0\n",
      "Uninstalling transformers-4.26.0:\n",
      "Successfully uninstalled transformers-4.26.0\n",
      "Attempting uninstall: datasets\n",
      "Found existing installation: datasets 2.16.1\n",
      "Uninstalling datasets-2.16.1:\n",
      "Successfully uninstalled datasets-2.16.1\n",
      "Successfully installed accelerate-0.27.2 datasets-2.19.1 peft-0.9.0 tokenizers-0.15.2 transformers-4.36.2\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.1.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2025-06-29 22:46:47,462 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-06-29 22:46:47,463 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-06-29 22:46:47,509 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-06-29 22:46:47,556 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-06-29 22:46:47,602 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-06-29 22:46:47,621 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"per_device_train_batch_size\": 4\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2025-06-29-22-42-20-036\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://likhits-news-summarizer/codetar/code.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"epochs\":1,\"per_device_train_batch_size\":4}\n",
      "SM_USER_ENTRY_POINT=train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://likhits-news-summarizer/codetar/code.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"per_device_train_batch_size\":4},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2025-06-29-22-42-20-036\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://likhits-news-summarizer/codetar/code.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train.py\"}\n",
      "SM_USER_ARGS=[\"--epochs\",\"1\",\"--per_device_train_batch_size\",\"4\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_EPOCHS=1\n",
      "SM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=4\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 train.py --epochs 1 --per_device_train_batch_size 4\n",
      "2025-06-29 22:46:47,663 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO] Loading dataset...\n",
      "Downloading readme: 0.00B [00:00, ?B/s]\n",
      "Downloading readme: 15.6kB [00:00, 29.8MB/s]\n",
      "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]\n",
      "Downloading data:   8%|▊         | 21.0M/257M [00:00<00:01, 173MB/s]\n",
      "Downloading data:  25%|██▍       | 62.9M/257M [00:00<00:00, 291MB/s]\n",
      "Downloading data:  45%|████▍     | 115M/257M [00:00<00:00, 344MB/s]\n",
      "Downloading data:  61%|██████▏   | 157M/257M [00:00<00:00, 351MB/s]\n",
      "Downloading data:  78%|███████▊  | 199M/257M [00:00<00:00, 353MB/s]\n",
      "Downloading data:  94%|█████████▍| 241M/257M [00:00<00:00, 372MB/s]\n",
      "Downloading data: 100%|██████████| 257M/257M [00:00<00:00, 348MB/s]\n",
      "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]\n",
      "Downloading data:  12%|█▏        | 31.5M/257M [00:00<00:00, 254MB/s]\n",
      "Downloading data:  29%|██▊       | 73.4M/257M [00:00<00:00, 319MB/s]\n",
      "Downloading data:  45%|████▍     | 115M/257M [00:00<00:00, 351MB/s]\n",
      "Downloading data:  61%|██████▏   | 157M/257M [00:00<00:00, 368MB/s]\n",
      "Downloading data:  78%|███████▊  | 199M/257M [00:00<00:00, 377MB/s]\n",
      "Downloading data:  98%|█████████▊| 252M/257M [00:00<00:00, 402MB/s]\n",
      "Downloading data: 100%|██████████| 257M/257M [00:00<00:00, 373MB/s]\n",
      "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]\n",
      "Downloading data:  12%|█▏        | 31.5M/259M [00:00<00:00, 263MB/s]\n",
      "Downloading data:  28%|██▊       | 73.4M/259M [00:00<00:00, 345MB/s]\n",
      "Downloading data:  44%|████▍     | 115M/259M [00:00<00:00, 345MB/s]\n",
      "Downloading data:  61%|██████    | 157M/259M [00:00<00:00, 352MB/s]\n",
      "Downloading data:  77%|███████▋  | 199M/259M [00:00<00:00, 327MB/s]\n",
      "Downloading data:  93%|█████████▎| 241M/259M [00:00<00:00, 333MB/s]\n",
      "Downloading data: 100%|██████████| 259M/259M [00:00<00:00, 336MB/s]\n",
      "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]\n",
      "Downloading data:  60%|██████    | 21.0M/34.7M [00:00<00:00, 200MB/s]\n",
      "Downloading data: 100%|██████████| 34.7M/34.7M [00:00<00:00, 252MB/s]\n",
      "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]\n",
      "Downloading data:  35%|███▍      | 10.5M/30.0M [00:00<00:00, 55.6MB/s]\n",
      "Downloading data: 100%|██████████| 30.0M/30.0M [00:00<00:00, 104MB/s]\n",
      "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]\n",
      "Generating train split:   2%|▏         | 7000/287113 [00:00<00:04, 63874.13 examples/s]\n",
      "Generating train split:   6%|▌         | 17000/287113 [00:00<00:03, 76926.34 examples/s]\n",
      "Generating train split:   9%|▉         | 27000/287113 [00:00<00:03, 79454.04 examples/s]\n",
      "Generating train split:  12%|█▏        | 35000/287113 [00:00<00:03, 77986.03 examples/s]\n",
      "Generating train split:  15%|█▍        | 43000/287113 [00:00<00:03, 73656.98 examples/s]\n",
      "Generating train split:  18%|█▊        | 51000/287113 [00:00<00:03, 74450.37 examples/s]\n",
      "Generating train split:  21%|██        | 59000/287113 [00:00<00:03, 73768.19 examples/s]\n",
      "Generating train split:  23%|██▎       | 67000/287113 [00:00<00:03, 71457.21 examples/s]\n",
      "Generating train split:  26%|██▌       | 75000/287113 [00:01<00:03, 70198.98 examples/s]\n",
      "Generating train split:  30%|██▉       | 86000/287113 [00:01<00:03, 65906.31 examples/s]\n",
      "Generating train split:  33%|███▎      | 94000/287113 [00:01<00:02, 64588.39 examples/s]\n",
      "Generating train split:  35%|███▌      | 101705/287113 [00:01<00:02, 65742.73 examples/s]\n",
      "Generating train split:  38%|███▊      | 109705/287113 [00:01<00:02, 67759.49 examples/s]\n",
      "Generating train split:  41%|████      | 117705/287113 [00:01<00:02, 69475.36 examples/s]\n",
      "Generating train split:  44%|████▍     | 125705/287113 [00:01<00:02, 70062.51 examples/s]\n",
      "Generating train split:  47%|████▋     | 133705/287113 [00:01<00:02, 70539.27 examples/s]\n",
      "Generating train split:  49%|████▉     | 141705/287113 [00:02<00:02, 71778.73 examples/s]\n",
      "Generating train split:  52%|█████▏    | 149705/287113 [00:02<00:01, 71967.66 examples/s]\n",
      "Generating train split:  55%|█████▍    | 157705/287113 [00:02<00:01, 72414.64 examples/s]\n",
      "Generating train split:  58%|█████▊    | 165705/287113 [00:02<00:01, 72497.94 examples/s]\n",
      "Generating train split:  61%|██████    | 174705/287113 [00:02<00:01, 75212.77 examples/s]\n",
      "Generating train split:  64%|██████▍   | 183705/287113 [00:02<00:01, 76165.16 examples/s]\n",
      "Generating train split:  67%|██████▋   | 192409/287113 [00:02<00:01, 75965.50 examples/s]\n",
      "Generating train split:  70%|███████   | 201409/287113 [00:02<00:01, 77040.69 examples/s]\n",
      "Generating train split:  74%|███████▎  | 211409/287113 [00:02<00:00, 78595.05 examples/s]\n",
      "Generating train split:  77%|███████▋  | 220409/287113 [00:03<00:00, 79214.35 examples/s]\n",
      "Generating train split:  80%|███████▉  | 229409/287113 [00:03<00:00, 77175.68 examples/s]\n",
      "Generating train split:  83%|████████▎ | 237409/287113 [00:03<00:00, 73713.95 examples/s]\n",
      "Generating train split:  85%|████████▌ | 245409/287113 [00:03<00:00, 72199.44 examples/s]\n",
      "Generating train split:  88%|████████▊ | 253409/287113 [00:03<00:00, 70007.16 examples/s]\n",
      "Generating train split:  91%|█████████ | 261409/287113 [00:03<00:00, 68942.45 examples/s]\n",
      "Generating train split:  94%|█████████▍| 269409/287113 [00:03<00:00, 70054.75 examples/s]\n",
      "Generating train split:  97%|█████████▋| 277409/287113 [00:03<00:00, 70559.58 examples/s]\n",
      "Generating train split:  99%|█████████▉| 285409/287113 [00:03<00:00, 69208.27 examples/s]\n",
      "Generating train split: 100%|██████████| 287113/287113 [00:03<00:00, 71978.00 examples/s]\n",
      "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]\n",
      "Generating validation split:  60%|█████▉    | 8000/13368 [00:00<00:00, 71030.46 examples/s]\n",
      "Generating validation split: 100%|██████████| 13368/13368 [00:00<00:00, 66708.29 examples/s]\n",
      "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]\n",
      "Generating test split:  78%|███████▊  | 9000/11490 [00:00<00:00, 73064.71 examples/s]\n",
      "Generating test split: 100%|██████████| 11490/11490 [00:00<00:00, 71372.58 examples/s]\n",
      "Map:   0%|          | 0/1 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 196.11 examples/s]\n",
      "Map:   0%|          | 0/1 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 145.03 examples/s]\n",
      "[INFO] Starting training...\n",
      "0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[2025-06-29 22:47:02.092 algo-1:66 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2025-06-29 22:47:02.233 algo-1:66 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2025-06-29 22:47:02.234 algo-1:66 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2025-06-29 22:47:02.234 algo-1:66 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2025-06-29 22:47:02.234 algo-1:66 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2025-06-29 22:47:02.235 algo-1:66 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "{'train_runtime': 1.1996, 'train_samples_per_second': 0.834, 'train_steps_per_second': 0.834, 'train_loss': 13.077900886535645, 'epoch': 1.0}\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "[INFO] Training complete.\n",
      "[INFO] Merging LoRA weights...\n",
      "[INFO] Saving model and tokenizer to /opt/ml/model\n",
      "[INFO] Removing invalid added_tokens.json...\n",
      "2025-06-29 22:47:04,425 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-06-29 22:47:04,425 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-06-29 22:47:04,425 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2025-06-29 22:47:16 Uploading - Uploading generated training model\n",
      "2025-06-29 22:47:39 Completed - Training job completed\n",
      "Training seconds: 276\n",
      "Billable seconds: 276\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "role = \"arn:aws:iam::727646472417:role/service-role/AmazonSageMaker-ExecutionRole-20250205T011531\" \n",
    "bucket_name = \"likhits-news-summarizer\" \n",
    "\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"train.py\",                        \n",
    "    source_dir=f\"s3://{bucket_name}/codetar/code.tar.gz\",                    \n",
    "    output_path=f\"s3://{bucket_name}/output\",                 \n",
    "    instance_type=\"ml.g4dn.xlarge\",                      \n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    transformers_version=\"4.26\",\n",
    "    pytorch_version=\"1.13\",\n",
    "    py_version=\"py39\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": 1,\n",
    "        \"per_device_train_batch_size\": 4\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "huggingface_estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
